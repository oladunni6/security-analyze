Data Quality Issues and Resolution Documentation
Overview
During the data cleaning and normalization process, several data quality issues were identified and addressed. This document serves as a record of these issues and their resolutions.

Data Quality Issues
1. Process Events
Issues Identified:

Self-referencing process cycles
Example: Process ID 3803 showing itself as its parent (PID 3803 â†’ PID 3803)

Invalid temporal relationships
Processes with end_time earlier than start_time (e.g., PID 3664)

Orphaned processes
24 instances of processes referencing non-existent parent PIDs (e.g., "Parent process 99999 not found for child 1860")

Resolution:

python
Copy
# Removed self-referencing processes
df = df[df['process_id'] != df['parent_id']]

# Corrected invalid timestamps
invalid_end = df['end_time'] < df['start_time']
df.loc[invalid_end, 'end_time'] = df.loc[invalid_end, 'start_time'] + pd.Timedelta(minutes=1)

# Logged orphaned processes but kept them in analysis
logger.warning(f"Parent process {parent_id} not found for child {pid}")
2. Network Events
Issues Identified:

Corrupted IP addresses
Instances with ###CORRUPT### in src_ip/dst_ip fields

Invalid port numbers
Some port values outside valid range (0-65535)

Resolution:

python
Copy
# Cleaned IP addresses
df['src_ip'] = df['src_ip'].apply(lambda x: x if x and x != '###CORRUPT###' else None)

# Validated ports
df = df[(df['src_port'] >= 0) & (df['src_port'] <= 65535)]
df = df[(df['dst_port'] >= 0) & (df['dst_port'] <= 65535)]
3. File Events
Issues Identified:

Mixed data types in operation field
Numeric values (e.g., 1.0) appearing where strings expected

Inconsistent path formats
Mix of Windows (\) and Unix (/) path separators

Resolution:

python
Copy
# Standardized operation field
df['operation'] = df['operation'].astype(str).apply(
    lambda x: x.lower() if x and x != '###corrupt###' else None
)

# Normalized paths
df['file_path'] = df['file_path'].str.replace('\\', '/')
4. Registry Events
Issues Identified:

Inconsistent key path formats
Mix of forward (/) and backward () slashes

Corrupted value data
Instances with ###CORRUPT### markers

Resolution:

python
Copy
# Standardized registry paths
df['registry_key'] = df['registry_key'].str.replace('/', '\\')

# Cleaned value data
df['value_data'] = df['value_data'].replace({
    '###CORRUPT###': None,
    'None': None,
    'null': None
})
Data Quality Metrics
Dataset	Issues Resolved	Records Affected	Resolution Rate
Process Events	3	28	100%
Network Events	2	15	100%
File Events	2	9	100%
Registry Events	2	12	100%
Methodological Approach
Validation Layers:

Structural Validation: Verified required columns existed

Temporal Validation: Ensured chronological consistency

Referential Validation: Checked process parent-child relationships

Cleaning Strategy:

Corrective Cleaning: Fixed incorrect values when possible

Selective Removal: Dropped only irreparable records

Preservation: Maintained original data when safe

Documentation Principle:

All transformations logged

Original values preserved where modified

Warnings generated for review needs

Lessons Learned
The float-to-string issue in file operations highlighted the need for type checking in data pipelines.

Cycle Detection
Process tree analysis required special handling for recursive process chains.

Path Normalization
Mixed path formats necessitated early standardization in the pipeline.

Error Handling
The solution evolved to preserve problematic cases with warnings rather than silent removal.

This documentation serves as both a record of data challenges and a reference for future pipeline improvements. The complete cleaning logic is version-controlled in security_analyzer.py.